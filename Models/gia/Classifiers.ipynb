{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce33d8db-b9ec-4786-b60e-7a8312bfe903",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444d13ac-30f2-47b1-9808-e3273fb567e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/03 16:21:57 WARN Utils: Your hostname, Gias-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.100 instead (on interface en0)\n",
      "23/12/03 16:21:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/03 16:21:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "df = spark.read.csv(\"KO.csv\", header=True, inferSchema=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba6b54-f5d3-430f-ad8b-ca19a34042da",
   "metadata": {},
   "source": [
    "### Buy - Hold - Sell\n",
    "https://www.investopedia.com/articles/technical/073001.asp\n",
    "\n",
    "Using the stochastics \"D\" line formula:\n",
    "$D= 100 \\bigg (\\frac{H3}{L3} \\bigg)$ \n",
    "\n",
    "Where, H3 is the Highest of the three previous stock prices and L3 is the lowest price in the same three day period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2ca8d7-63f3-48c1-9cce-2297e9ad2005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.date(1962, 1, 2), Open=0.263021, High=0.270182, Low=0.263021, Close=0.263021, Adj Close=0.048528, Volume=806400)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b8858e1-d5a2-44d6-9251-7d33e04c953f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowSpec = Window().orderBy(\"Date\")\n",
    "\n",
    "# Calculate H3 and L3 using the window functions\n",
    "df = df.withColumn(\"H3\", F.max(\"Adj Close\").over(windowSpec.rowsBetween(-2, 0)))\n",
    "df = df.withColumn(\"L3\", F.min(\"Adj Close\").over(windowSpec.rowsBetween(-2, 0)))\n",
    "\n",
    "# Calculate the D line\n",
    "df = df.withColumn(\"D\", 100 * (F.col(\"H3\") / F.col(\"L3\")))\n",
    "\n",
    "# Create a binary class column based on the D line buy = 0, sell = 1\n",
    "df = df.withColumn(\"Class\", F.when(F.col(\"D\") > 102, 1).otherwise(0))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9f597-39ee-4ff2-b773-04848f8f7ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8c40de-4c82-4c1b-936d-f0398c016008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/03 16:22:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/12/03 16:22:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.5375634792536022\n",
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/03 16:22:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/12/03 16:22:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "nb_df = df.drop(\"Date\", \"D\", \"label\", \"L3\", \"H3\")\n",
    "\n",
    "outcome = \"Class\"\n",
    "\n",
    "# Compile all columns that are not the outcome\n",
    "feature_cols = [col for col in nb_df.columns if col not in [outcome, \"D\", \"label\", \"L3\", \"H3\"]]\n",
    "\n",
    "# Convert the \"Class\" column to a numeric type using StringIndexer\n",
    "indexer = StringIndexer(inputCol=outcome, outputCol=\"label\")\n",
    "nb_df = indexer.fit(nb_df).transform(nb_df)\n",
    "\n",
    "# Create a vector assembler\n",
    "vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"nb_features\")\n",
    "\n",
    "# Transform the DataFrame using the vector assembler\n",
    "nb_df = vector_assembler.transform(nb_df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = nb_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Calculate class weights based on the class distribution\n",
    "class_counts = train_data.groupBy(\"label\").count()\n",
    "total_count = train_data.count()\n",
    "\n",
    "# Calculate class weights based on the class distribution\n",
    "train_data = train_data.join(class_counts.withColumn(\"classWeight\", F.col(\"count\") / total_count), \"label\")\n",
    "\n",
    "# Create a Naive Bayes model\n",
    "naive_bayes = NaiveBayes(featuresCol=\"nb_features\", labelCol=\"label\", smoothing=0.001, weightCol=\"classWeight\")\n",
    "\n",
    "# Train the model\n",
    "naive_bayes_model = naive_bayes.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = naive_bayes_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "area_under_roc = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the area under ROC\n",
    "print(f\"Area under ROC: {area_under_roc}\")\n",
    "predictions.select(\"label\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5465b-6e7b-4581-98a9-cbdbe51ac57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9619f8-11a3-4deb-9b64-931dea19b406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6820412168792934\n",
      "+-----+----------+\n",
      "|Class|prediction|\n",
      "+-----+----------+\n",
      "|    1|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/03 16:22:15 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "svm_df = spark.read.csv(\"KO_class.csv\", header=True, inferSchema=True) \n",
    "# Drop unnecessary columns\n",
    "svm_df = svm_df.drop(\"label\",\"Date\", \"H3\", \"L3\", \"D\")\n",
    "\n",
    "\n",
    "# Define outcome and feature columns\n",
    "outcome = \"Class\"\n",
    "feature_cols = [col for col in svm_df.columns if col not in outcome]\n",
    "\n",
    "# Vector assembler for feature transformation\n",
    "vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"svm_features\")\n",
    "svm_df = vector_assembler.transform(svm_df)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = svm_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Linear SVM model\n",
    "svm_classifier = LinearSVC(featuresCol=\"svm_features\", labelCol=\"Class\", maxIter=10)\n",
    "svm_model = svm_classifier.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(svm_predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"SVM Accuracy: {accuracy}\")\n",
    "\n",
    "# View predictions\n",
    "svm_predictions.select(\"Class\", \"prediction\").show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
