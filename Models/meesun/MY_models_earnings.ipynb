{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/08 16:38:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = SparkSession.builder.master(\"local\").appName(\"mllib_classifier\").getOrCreate()\n",
    "spark = SparkSession.builder.appName(\"StockPricePrediction\").getOrCreate()\n",
    "\n",
    "# Load training data\n",
    "filename = \"KOv3.csv\"\n",
    "data = spark.read.csv(filename, inferSchema=True, header = True)\n",
    "#data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close',\n",
       " 'PercentChangeClose',\n",
       " 'Percent100',\n",
       " 'Volume',\n",
       " 'MarketCap',\n",
       " 'EnterpriseValue',\n",
       " 'PeRatio',\n",
       " 'PsRatio',\n",
       " 'PbRatio',\n",
       " 'EnterprisesValueRevenueRatio',\n",
       " 'EnterprisesValueEBITDARatio',\n",
       " 'TotalRevenue',\n",
       " 'OperatingRevenue',\n",
       " 'CostOfRevenue',\n",
       " 'GrossProfit',\n",
       " 'OperatingExpense',\n",
       " 'SellingGeneralAndAdministration',\n",
       " 'OperatingIncome',\n",
       " 'OtherIncomeExpense',\n",
       " 'PretaxIncome',\n",
       " 'TaxProvision',\n",
       " 'NetIncomeCommonStockholders',\n",
       " 'NetIncome',\n",
       " 'NetIncomeIncludingNoncontrollingInterests',\n",
       " 'NetIncomeContinuousOperations',\n",
       " 'DilutedNIAvailtoComStockholders',\n",
       " 'BasicEPS',\n",
       " 'DilutedEPS',\n",
       " 'BasicAverageShares',\n",
       " 'DilutedAverageShares',\n",
       " 'TotalOperatingIncomeAsReported',\n",
       " 'TotalExpenses',\n",
       " 'NetIncomeFromContinuingAndDiscontinuedOperation',\n",
       " 'NormalizedIncome',\n",
       " 'EBIT',\n",
       " 'EBITDA',\n",
       " 'ReconciledCostOfRevenue',\n",
       " 'ReconciledDepreciation',\n",
       " 'NetIncomeFromContinuingOperationNetMinorityInterest',\n",
       " 'NormalizedEBITDA',\n",
       " 'TaxRateForCalcs',\n",
       " 'TaxEffectOfUnusualItems',\n",
       " 'TotalAssets',\n",
       " 'CurrentAssets',\n",
       " 'CashCashEquivalentsAndShortTermInvestments',\n",
       " 'CashAndCashEquivalents',\n",
       " 'Receivables',\n",
       " 'Inventory',\n",
       " 'TotalNonCurrentAssets',\n",
       " 'NetPPE',\n",
       " 'GrossPPE',\n",
       " 'AccumulatedDepreciation',\n",
       " 'GoodwillAndOtherIntangibleAssets',\n",
       " 'OtherIntangibleAssets',\n",
       " 'OtherNonCurrentAssets',\n",
       " 'TotalLiabilitiesNetMinorityInterest',\n",
       " 'CurrentLiabilities',\n",
       " 'PayablesAndAccruedExpenses',\n",
       " 'Payables',\n",
       " 'AccountsPayable',\n",
       " 'CurrentDebtAndCapitalLeaseObligation',\n",
       " 'CurrentDebt',\n",
       " 'TotalNonCurrentLiabilitiesNetMinorityInterest',\n",
       " 'LongTermDebtAndCapitalLeaseObligation',\n",
       " 'LongTermDebt',\n",
       " 'NonCurrentDeferredLiabilities',\n",
       " 'NonCurrentDeferredTaxesLiabilities',\n",
       " 'OtherNonCurrentLiabilities',\n",
       " 'TotalEquityGrossMinorityInterest',\n",
       " 'StockholdersEquity',\n",
       " 'RetainedEarnings',\n",
       " 'TotalCapitalization',\n",
       " 'CommonStockEquity',\n",
       " 'NetTangibleAssets',\n",
       " 'WorkingCapital',\n",
       " 'InvestedCapital',\n",
       " 'TangibleBookValue',\n",
       " 'TotalDebt',\n",
       " 'ShareIssued',\n",
       " 'OrdinarySharesNumber',\n",
       " 'OperatingCashFlow',\n",
       " 'CashFlowFromContinuingOperatingActivities',\n",
       " 'NetIncomeFromContinuingOperations',\n",
       " 'DepreciationAmortizationDepletion',\n",
       " 'DepreciationAndAmortization',\n",
       " 'DeferredTax',\n",
       " 'DeferredIncomeTax',\n",
       " 'InvestingCashFlow',\n",
       " 'CashFlowFromContinuingInvestingActivities',\n",
       " 'NetPPEPurchaseAndSale',\n",
       " 'PurchaseOfPPE',\n",
       " 'FinancingCashFlow',\n",
       " 'CashFlowFromContinuingFinancingActivities',\n",
       " 'NetIssuancePaymentsOfDebt',\n",
       " 'NetCommonStockIssuance',\n",
       " 'CommonStockIssuance',\n",
       " 'CommonStockPayments',\n",
       " 'EndCashPosition',\n",
       " 'ChangesInCash',\n",
       " 'EffectOfExchangeRateChanges',\n",
       " 'BeginningCashPosition',\n",
       " 'CapitalExpenditure',\n",
       " 'IssuanceOfCapitalStock',\n",
       " 'RepurchaseOfCapitalStock',\n",
       " 'FreeCashFlow']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Adj Close',\n",
       " 'Volume',\n",
       " 'MarketCap',\n",
       " 'EnterpriseValue',\n",
       " 'PeRatio',\n",
       " 'PsRatio',\n",
       " 'PbRatio',\n",
       " 'EnterprisesValueRevenueRatio',\n",
       " 'EnterprisesValueEBITDARatio',\n",
       " 'TotalRevenue',\n",
       " 'OperatingRevenue',\n",
       " 'CostOfRevenue',\n",
       " 'GrossProfit',\n",
       " 'OperatingExpense',\n",
       " 'SellingGeneralAndAdministration',\n",
       " 'OperatingIncome',\n",
       " 'OtherIncomeExpense',\n",
       " 'PretaxIncome',\n",
       " 'TaxProvision',\n",
       " 'NetIncomeCommonStockholders',\n",
       " 'NetIncome',\n",
       " 'NetIncomeIncludingNoncontrollingInterests',\n",
       " 'NetIncomeContinuousOperations',\n",
       " 'DilutedNIAvailtoComStockholders',\n",
       " 'BasicEPS',\n",
       " 'DilutedEPS',\n",
       " 'BasicAverageShares',\n",
       " 'DilutedAverageShares',\n",
       " 'TotalOperatingIncomeAsReported',\n",
       " 'TotalExpenses',\n",
       " 'NetIncomeFromContinuingAndDiscontinuedOperation',\n",
       " 'NormalizedIncome',\n",
       " 'EBIT',\n",
       " 'EBITDA',\n",
       " 'ReconciledCostOfRevenue',\n",
       " 'ReconciledDepreciation',\n",
       " 'NetIncomeFromContinuingOperationNetMinorityInterest',\n",
       " 'NormalizedEBITDA',\n",
       " 'TaxRateForCalcs',\n",
       " 'TotalAssets',\n",
       " 'CurrentAssets',\n",
       " 'CashCashEquivalentsAndShortTermInvestments',\n",
       " 'CashAndCashEquivalents',\n",
       " 'Receivables',\n",
       " 'Inventory',\n",
       " 'TotalNonCurrentAssets',\n",
       " 'NetPPE',\n",
       " 'GrossPPE',\n",
       " 'AccumulatedDepreciation',\n",
       " 'GoodwillAndOtherIntangibleAssets',\n",
       " 'OtherIntangibleAssets',\n",
       " 'OtherNonCurrentAssets',\n",
       " 'TotalLiabilitiesNetMinorityInterest',\n",
       " 'CurrentLiabilities',\n",
       " 'PayablesAndAccruedExpenses',\n",
       " 'Payables',\n",
       " 'AccountsPayable',\n",
       " 'CurrentDebtAndCapitalLeaseObligation',\n",
       " 'CurrentDebt',\n",
       " 'TotalNonCurrentLiabilitiesNetMinorityInterest',\n",
       " 'LongTermDebtAndCapitalLeaseObligation',\n",
       " 'LongTermDebt',\n",
       " 'NonCurrentDeferredLiabilities',\n",
       " 'NonCurrentDeferredTaxesLiabilities',\n",
       " 'OtherNonCurrentLiabilities',\n",
       " 'TotalEquityGrossMinorityInterest',\n",
       " 'StockholdersEquity',\n",
       " 'RetainedEarnings',\n",
       " 'TotalCapitalization',\n",
       " 'CommonStockEquity',\n",
       " 'NetTangibleAssets',\n",
       " 'WorkingCapital',\n",
       " 'InvestedCapital',\n",
       " 'TangibleBookValue',\n",
       " 'TotalDebt',\n",
       " 'ShareIssued',\n",
       " 'OrdinarySharesNumber',\n",
       " 'OperatingCashFlow',\n",
       " 'CashFlowFromContinuingOperatingActivities',\n",
       " 'NetIncomeFromContinuingOperations',\n",
       " 'DepreciationAmortizationDepletion',\n",
       " 'DepreciationAndAmortization',\n",
       " 'DeferredTax',\n",
       " 'DeferredIncomeTax',\n",
       " 'InvestingCashFlow',\n",
       " 'CashFlowFromContinuingInvestingActivities',\n",
       " 'NetPPEPurchaseAndSale',\n",
       " 'PurchaseOfPPE',\n",
       " 'FinancingCashFlow',\n",
       " 'CashFlowFromContinuingFinancingActivities',\n",
       " 'NetIssuancePaymentsOfDebt',\n",
       " 'NetCommonStockIssuance',\n",
       " 'CommonStockIssuance',\n",
       " 'CommonStockPayments',\n",
       " 'EndCashPosition',\n",
       " 'ChangesInCash',\n",
       " 'EffectOfExchangeRateChanges',\n",
       " 'BeginningCashPosition',\n",
       " 'CapitalExpenditure',\n",
       " 'IssuanceOfCapitalStock',\n",
       " 'RepurchaseOfCapitalStock',\n",
       " 'FreeCashFlow']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data.drop('Date','PercentChangeClose', 'Percent100','TaxEffectOfUnusualItems')\n",
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.drop('Date','Percent100','Adj Close','TaxEffectOfUnusualItems')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'PercentChangeClose', 'Percent100', 'Volume', 'MarketCap', 'EnterpriseValue', 'PeRatio', 'PsRatio', 'PbRatio', 'EnterprisesValueRevenueRatio', 'EnterprisesValueEBITDARatio', 'TotalRevenue', 'OperatingRevenue', 'CostOfRevenue', 'GrossProfit', 'OperatingExpense', 'SellingGeneralAndAdministration', 'OperatingIncome', 'OtherIncomeExpense', 'PretaxIncome', 'TaxProvision', 'NetIncomeCommonStockholders', 'NetIncome', 'NetIncomeIncludingNoncontrollingInterests', 'NetIncomeContinuousOperations', 'DilutedNIAvailtoComStockholders', 'BasicEPS', 'DilutedEPS', 'BasicAverageShares', 'DilutedAverageShares', 'TotalOperatingIncomeAsReported', 'TotalExpenses', 'NetIncomeFromContinuingAndDiscontinuedOperation', 'NormalizedIncome', 'EBIT', 'EBITDA', 'ReconciledCostOfRevenue', 'ReconciledDepreciation', 'NetIncomeFromContinuingOperationNetMinorityInterest', 'NormalizedEBITDA', 'TaxRateForCalcs', 'TaxEffectOfUnusualItems', 'TotalAssets', 'CurrentAssets', 'CashCashEquivalentsAndShortTermInvestments', 'CashAndCashEquivalents', 'Receivables', 'Inventory', 'TotalNonCurrentAssets', 'NetPPE', 'GrossPPE', 'AccumulatedDepreciation', 'GoodwillAndOtherIntangibleAssets', 'OtherIntangibleAssets', 'OtherNonCurrentAssets', 'TotalLiabilitiesNetMinorityInterest', 'CurrentLiabilities', 'PayablesAndAccruedExpenses', 'Payables', 'AccountsPayable', 'CurrentDebtAndCapitalLeaseObligation', 'CurrentDebt', 'TotalNonCurrentLiabilitiesNetMinorityInterest', 'LongTermDebtAndCapitalLeaseObligation', 'LongTermDebt', 'NonCurrentDeferredLiabilities', 'NonCurrentDeferredTaxesLiabilities', 'OtherNonCurrentLiabilities', 'TotalEquityGrossMinorityInterest', 'StockholdersEquity', 'RetainedEarnings', 'TotalCapitalization', 'CommonStockEquity', 'NetTangibleAssets', 'WorkingCapital', 'InvestedCapital', 'TangibleBookValue', 'TotalDebt', 'ShareIssued', 'OrdinarySharesNumber', 'OperatingCashFlow', 'CashFlowFromContinuingOperatingActivities', 'NetIncomeFromContinuingOperations', 'DepreciationAmortizationDepletion', 'DepreciationAndAmortization', 'DeferredTax', 'DeferredIncomeTax', 'InvestingCashFlow', 'CashFlowFromContinuingInvestingActivities', 'NetPPEPurchaseAndSale', 'PurchaseOfPPE', 'FinancingCashFlow', 'CashFlowFromContinuingFinancingActivities', 'NetIssuancePaymentsOfDebt', 'NetCommonStockIssuance', 'CommonStockIssuance', 'CommonStockPayments', 'EndCashPosition', 'ChangesInCash', 'EffectOfExchangeRateChanges', 'BeginningCashPosition', 'CapitalExpenditure', 'IssuanceOfCapitalStock', 'RepurchaseOfCapitalStock', 'FreeCashFlow']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = data2.columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pyspark to add ROI and buy/sell columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/08 16:38:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "+----------+---------+------------------+----------+-------+-------+-------+------------+-----------+----------------------------+---------------------------+----------------+---------------+----------+--------+-------------+----------------+----------+----------+-----------+----------------------+-----------+-----------+-----------+----------------+\n",
      "|      Date|Adj Close|PercentChangeClose|Percent100|PeRatio|PsRatio|PbRatio|TotalRevenue|GrossProfit|EnterprisesValueRevenueRatio|EnterprisesValueEBITDARatio|OperatingExpense|OperatingIncome| NetIncome|BasicEPS|TotalExpenses|NormalizedIncome|      EBIT|    EBITDA|TotalAssets|CashAndCashEquivalents|     NetPPE|   GrossPPE|  TotalDebt|RetainedEarnings|\n",
      "+----------+---------+------------------+----------+-------+-------+-------+------------+-----------+----------------------------+---------------------------+----------------+---------------+----------+--------+-------------+----------------+----------+----------+-----------+----------------------+-----------+-----------+-----------+----------------+\n",
      "| 9/30/2023|56.490002|             0.919|     91.94| 23.228|  5.509|  9.305| 11953000000| 7296000000|                       22.42|                     63.883|      4026000000|     3270000000|3087000000|    0.71|   8683000000|      3087000000|3905000000|4195000000|97578000000|           11883000000| 8860000000|18048000000|40171000000|     73793000000|\n",
      "| 6/30/2023|61.442528|             0.973|    97.275| 26.529|  6.019| 10.326| 11972000000| 7060000000|                      24.098|                     81.611|      4659000000|     2401000000|2547000000|    0.59|   9571000000|      2547000000|3254000000|3535000000|98456000000|           12564000000| 9706000000|19233000000|41625000000|     72695000000|\n",
      "| 3/31/2023|63.164001|             1.054|   105.418| 28.324|  6.275|  11.13| 10980000000| 6663000000|                       26.94|                     62.789|      3296000000|     3367000000|3107000000|    0.72|   7613000000|      3107000000|4425000000|4711000000|97404000000|           12004000000| 9848000000|19241000000|42400000000|     72137000000|\n",
      "|12/31/2022|  59.9179|             1.032|   103.183| 27.899|  6.537| 12.072| 10125000000| 5612000000|                      29.773|                     96.898|      3537000000|     2075000000|2031000000|    0.47|   8050000000|      2031000000|2804000000|3111000000|92763000000|            9519000000| 9841000000|19075000000|39149000000|     71019000000|\n",
      "| 9/30/2022|58.069668|             0.939|    93.948| 25.464|  5.898| 10.529| 11063000000| 6497000000|                      24.633|                     69.008|      3409000000|     3088000000|2825000000|    0.65|   7975000000|      2825000000|3642000000|3949000000|92471000000|           10127000000| 9243000000|18235000000|39587000000|     70893000000|\n",
      "| 6/30/2022|61.810516|               1.0|   100.037| 26.544|  6.815| 10.977| 11325000000| 6495000000|                      26.849|                    108.439|      4154000000|     2341000000|1905000000|    0.44|   8984000000|      1905000000|2482000000|2804000000|93169000000|            8976000000| 9462000000|18561000000|41901000000|     69970000000|\n",
      "| 3/31/2022|61.787926|             1.067|   106.711| 27.556|  6.961| 11.686| 10491000000| 6400000000|                      28.492|                     75.405|      2995000000|     3405000000|2781000000|    0.64|   7086000000|      2781000000|3640000000|3964000000|94064000000|            7681000000| 9784000000|18888000000|41701000000|     69969000000|\n",
      "|12/31/2021|57.901939|             1.091|   109.071| 29.167|   6.79| 11.547|  9464000000| 5376000000|                      29.895|                     81.628|      3704000000|     1672000000|2414000000|    0.56|   7792000000|      2414000000|3125000000|3466000000|94354000000|            9684000000| 9920000000|18862000000|42761000000|     69094000000|\n",
      "| 9/30/2021|53.086636|             0.996|    99.589| 28.059|  6.239|  10.18| 10042000000| 6065000000|                      25.439|                     69.874|      3167000000|     2898000000|2471000000|    0.57|   7144000000|      2471000000|3294000000|3656000000|90606000000|           11301000000|10058000000|19211000000|41708000000|     68494000000|\n",
      "| 6/30/2021|53.305889|             1.064|   106.446| 32.401|  6.999| 11.462| 10129000000| 6342000000|                      26.232|                     55.574|      3326000000|     3016000000|2641000000|    0.61|   7113000000|      2641000000|4398000000|4781000000|90194000000|            9188000000|10547000000|19909000000|42008000000|     67838000000|\n",
      "| 3/31/2021|50.077721|              1.13|   113.041| 29.447|  6.902|  11.77|  9020000000| 5515000000|                      28.716|                     72.535|      2793000000|     2722000000|2245000000|    0.52|   6298000000|      2245000000|3205000000|3571000000|89993000000|            8484000000|10673000000|19859000000|44983000000|     67009000000|\n",
      "|12/31/2020|44.300453|              1.01|   100.973| 28.415|   7.08|  12.68|  8611000000| 5033000000|                      31.084|                     86.314|      2695000000|     2338000000|1456000000|    0.34|   6273000000|      1456000000|2671000000|3101000000|87296000000|            6795000000|10777000000|19700000000|42793000000|     66555000000|\n",
      "| 9/30/2020|43.873634|             1.026|   102.559| 23.288|  6.216| 12.134|  8652000000| 5181000000|                      28.278|                      76.48|      2883000000|     2298000000|1737000000|     0.4|   6354000000|      1737000000|2841000000|3199000000|97184000000|           11385000000|10667000000|19544000000|52867000000|     66863000000|\n",
      "| 6/30/2020|42.778782|             1.039|   103.877| 19.259|  5.191| 10.568| 15751000000| 9367000000|                      14.261|                     37.098|      5006000000|     4361000000|4554000000|    1.06|  11390000000|      4554000000|5674000000|6055000000|94689000000|           10037000000|10695000000|19234000000|52333000000|     66888000000|\n",
      "| 3/31/2020|41.182129|             0.793|    79.268| 21.377|  5.122| 10.011|  8601000000| 5230000000|                      25.764|                     62.072|      2850000000|     2380000000|2775000000|    0.65|   6221000000|      2775000000|3203000000|3570000000|94013000000|           13561000000|10993000000|19278000000|50393000000|     66870000000|\n",
      "|12/31/2019|51.953102|             1.081|   108.095| 29.441|  7.108|  12.66|  9068000000| 5502000000|                      29.523|                     87.632|      3338000000|     2164000000|2042000000|    0.48|   6904000000|      2042000000|2655000000|3055000000|86381000000|            6480000000|10838000000|18921000000|42763000000|     65810000000|\n",
      "| 9/30/2019|48.062347|             1.042|   104.176| 31.836|  7.135| 12.828|  9507000000| 5740000000|                      27.487|                     70.915|      3241000000|     2499000000|2593000000|    0.61|   7008000000|      2593000000|3322000000|3685000000|87433000000|            7531000000|10217000000|19794000000|42476000000|     65481000000|\n",
      "| 6/30/2019|46.135609|             1.081|   108.114| 31.049|  6.788| 12.274|  9997000000| 6076000000|                      25.135|                     69.565|      3088000000|     2988000000|2607000000|    0.61|   7009000000|      2607000000|3285000000|3612000000|89996000000|            6731000000|10254000000|19806000000|45075000000|     64602000000|\n",
      "| 3/31/2019|42.673019|             1.028|   102.822| 29.847|  6.324| 11.778|  8020000000| 5030000000|                      28.378|                     86.241|      2694000000|     2336000000|1678000000|    0.39|   5684000000|      1621000000|2364000000|2639000000|88347000000|            5645000000| 8866000000|18140000000|44267000000|     63704000000|\n",
      "|12/31/2018|41.501797|             1.013|   101.317| 64.863|  6.304| 11.065|  7058000000| 4337000000|                      32.315|                    221.652|      2701000000|     1636000000| 870000000|     0.2|   5422000000|       735000000|1029000000|1029000000|83216000000|            9077000000| 9598000000|17611000000|44214000000|     63234000000|\n",
      "+----------+---------+------------------+----------+-------+-------+-------+------------+-----------+----------------------------+---------------------------+----------------+---------------+----------+--------+-------------+----------------+----------+----------+-----------+----------------------+-----------+-----------+-----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"SubsetColumns\").getOrCreate()\n",
    "\n",
    "# Define a list of columns you want to include in the subset\n",
    "selected_columns = [\"Date\", \"Adj Close\", \"PercentChangeClose\", \"Percent100\", \"PeRatio\", \"PsRatio\", \"PbRatio\",\"TotalRevenue\",\"GrossProfit\", \n",
    "                    \"EnterprisesValueRevenueRatio\", \"EnterprisesValueEBITDARatio\", \"OperatingExpense\", \n",
    "                    \"OperatingIncome\", \"NetIncome\", \"BasicEPS\", \"TotalExpenses\", \n",
    "                    \"NormalizedIncome\", \"EBIT\", \"EBITDA\", \"TotalAssets\", \"CashAndCashEquivalents\", \n",
    "                    \"NetPPE\", \"GrossPPE\", \"TotalDebt\", \"RetainedEarnings\"]\n",
    "\n",
    "# Use the select function to create a new DataFrame with the subset of columns\n",
    "new_df = data.select(selected_columns)\n",
    "\n",
    "# Show the new DataFrame\n",
    "#new_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+\n",
      "|PercentChangeClose|ROI                   |\n",
      "+------------------+----------------------+\n",
      "|0.919             |-0.08099999999999996  |\n",
      "|0.973             |-0.027000000000000024 |\n",
      "|1.054             |0.05400000000000005   |\n",
      "|1.032             |0.03200000000000003   |\n",
      "|0.939             |-0.061000000000000054 |\n",
      "|1.0               |0.0                   |\n",
      "|1.067             |0.06699999999999995   |\n",
      "|1.091             |0.09099999999999997   |\n",
      "|0.996             |-0.0040000000000000036|\n",
      "|1.064             |0.06400000000000006   |\n",
      "+------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.withColumn(\"ROI\", new_df[\"PercentChangeClose\"]-1)\n",
    "new_df.select(\"PercentChangeClose\",\"ROI\").show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"StringToFloatConversion\").getOrCreate()\n",
    "\n",
    "# Assuming you have a DataFrame called \"your_data\"\n",
    "# Replace \"your_data\" with your actual DataFrame name\n",
    "data = data  # Replace this with your actual DataFrame\n",
    "\n",
    "# Get the list of columns in the DataFrame\n",
    "all_columns = data.columns\n",
    "\n",
    "# Iterate through each column and update its type to float\n",
    "for column in all_columns:\n",
    "    data = data.withColumn(column, col(column).cast(\"float\"))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "data.describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(train_data)\n",
    "scaledData = scalerModel.transform(train_data)\n",
    "\n",
    "scaledData.select(\"high_price\",\"features\",\"scaledFeatures\").show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n",
      "|Date      |PercentChangeClose|prediction        |\n",
      "+----------+------------------+------------------+\n",
      "|12/31/1990|1.091             |1.0476167794366946|\n",
      "|12/31/1996|1.149             |1.0407488640151497|\n",
      "|12/31/1998|0.969             |1.0348461729772824|\n",
      "|12/31/2007|0.96              |1.0272884890613296|\n",
      "|12/31/2009|1.025             |1.0257556755414352|\n",
      "|12/31/2011|0.996             |1.0124203492868773|\n",
      "|12/31/2018|1.013             |1.0103571988105922|\n",
      "|3/31/1996 |1.085             |1.0429170208788934|\n",
      "|3/31/2006 |1.021             |1.0343950016438515|\n",
      "|3/31/2009 |1.018             |1.0287351312413817|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Print the weights and intercept for linear regression\\n#print(\"Weights: \" + str(model.coefficients))\\n#print(\"Intercept: \" + str(model.intercept))\\n\\n# Summarize the model over the training set and print out some metrics\\nsummary = model.summary\\nprint(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\\nprint(\"T Values: \" + str(summary.tValues))\\nprint(\"P Values: \" + str(summary.pValues))\\nprint(\"Dispersion: \" + str(summary.dispersion))\\nprint(\"Null Deviance: \" + str(summary.nullDeviance))\\nprint(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\\nprint(\"Deviance: \" + str(summary.deviance))\\nprint(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\\nprint(\"AIC: \" + str(summary.aic))\\nprint(\"Deviance Residuals: \")\\nsummary.residuals().show()\\n\\n# Make predictions on the test set\\n#predictions = model.transform(test_data)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "#spark = SparkSession.builder.appName(\"StockPricePrediction\").getOrCreate()\n",
    "\n",
    "# Assuming your data is in a DataFrame called \"data\"\n",
    "# Replace \"target_column\" with the actual column name of your target variable\n",
    "target_column = \"PercentChangeClose\"\n",
    "features_columns = [\"PeRatio\", \"PsRatio\", \"PbRatio\",\"TotalRevenue\",\"GrossProfit\", \n",
    "                    \"EnterprisesValueRevenueRatio\", \"EnterprisesValueEBITDARatio\", \"OperatingExpense\", \n",
    "                    \"OperatingIncome\", \"NetIncome\", \"BasicEPS\", \"TotalExpenses\", \n",
    "                    \"NormalizedIncome\", \"EBIT\", \"EBITDA\", \"TotalAssets\", \"CashAndCashEquivalents\", \n",
    "                    \"NetPPE\", \"GrossPPE\", \"TotalDebt\", \"RetainedEarnings\"]\n",
    "\n",
    "# Assemble the features into a vector\n",
    "assembler = VectorAssembler(inputCols=features_columns, outputCol=\"features\")\n",
    "#data_assembled = assembler.transform(new_df)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "#scalerModel = scaler.fit(data_assembled)\n",
    "#scaledData = scalerModel.transform(data_assembled)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr = GeneralizedLinearRegression(labelCol=target_column, featuresCol=\"scaledFeatures\",\n",
    "                      family=\"gaussian\", link=\"identity\",\n",
    "                       maxIter=10,\n",
    "                      regParam=0.3) \n",
    "                      #elasticNetParam=0.8)\n",
    "\n",
    "# Create a pipeline with the assembler, scaler, and the logistic regression model\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "#pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(train_data, test_data) = new_df.randomSplit([0.8, 0.2], seed=33)\n",
    "\n",
    "# Train the model\n",
    "#model = lr.fit(train_data)\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions on test set\n",
    "prediction = model.transform(test_data)\n",
    "prediction.select('Date','PercentChangeClose','prediction').show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS\n",
      "Root Mean Squared Error: 0.07373797746240673\n",
      "R Squared: -0.016135513273495272\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "#lrPred = model.transform(test_data)\n",
    "#lrPred = lrPred.withColumn(\"prediction\", F.abs(lrPred[\"prediction\"]))\n",
    "#lrPred.select(\"Date\",\"PercentChangeClose\",\"PercentChangeClose\",\"prediction\").show(100)\n",
    "\n",
    "ev = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"PercentChangeClose\")\n",
    "\n",
    "print(\"METRICS\")\n",
    "print(\"Root Mean Squared Error:\", ev.evaluate(prediction, {ev.metricName: \"rmse\"}))\n",
    "print(\"R Squared:\", ev.evaluate(prediction, {ev.metricName:'r2'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [1.4199395562645802,2.089593654516267,1.7317540518907564,3.0974314783278025,0.06616628675867332,-0.3794686590988214,1.092807470731824,1.028717187065099,-0.0784121685318791,-0.21579840518606752,-0.5901432978000233,-0.34274750462417086,-0.22524164109563483,-0.08103360123265795,-0.08103360123279121,-0.22798604575036938,0.028633745086646876,0.15078433692914878,-0.3277178007557816,-0.15223411075972867,0.24297475706119714,-0.2305005009238284,-0.21169402373238175,-0.08188976241312737,-0.08356902707137062,-0.13382328485103923,-0.15814789820528757,-0.08188976241306842,0.026183259678416764,0.06476206436822743,-0.18595125469698634,-0.14127458237594673,-0.1520894095167543,-0.05492991644451077,-0.175249004807556,-0.05592236443020898,0.17920064036963443,0.08455938302960614,-0.2345695974723,-0.7727719709369106,-0.10765009643436092,0.1286024134155814,-0.0936077361961899,0.3554993555023181,-0.2203292503776532,-0.3090146002030044,0.16157509079784826,-0.2609505667468731,1.0327364848374196,0.6457706970414571,-1.0609631339119925,-0.6654906420264438,-0.32381324604740674,0.7680253354633149,-0.21502856001157783,0.1724539755119024,0.24062826151933175,-0.2137537251588818,-0.0017055494431418153,0.18471593042555526,-0.03045012554469762,-0.14860331152331782,-0.1486033115233073,0.49171294079088673,0.5969224464002196,0.5969224464003114,-0.27864067715527313,-0.2786406771552894,0.3556962960230167,0.5885231183304345,0.4121019794487899,0.980506929489067,0.5815530101306077,0.416047568782456,-0.8460388539413959,-0.15000351456309632,0.42305274817472843,-0.8361986072260311,0.37594209176145854,0.23036876034132778,-0.5267941201104817,0.2602743736761938,0.19958100603455847,0.322671227008591,-0.772771970937219,-0.7727719709373239,-0.0314512195132655,-0.0314512195132678,-0.04878689766978242,0.027522655485185826,0.12960319776133739,-0.049920625894168416,-0.17617277610947174,-0.20786931060594357,0.7900002857916235,0.08949612583478989,-0.08149290817747906,0.09706845709655529,0.12733357169176604,-0.07579517560257569,-0.08709090516035699,0.1534873155423285,-0.04992062589438224,-0.0814929081772973,0.0970684570967621,0.27399486070485973]\n",
      "Intercept: 14.325654363942194\n",
      "Coefficient Standard Errors: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "T Values: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: degreesOfFreedom must be positive, but got -1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_265901/1717562679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coefficient Standard Errors: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficientStandardErrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"T Values: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"P Values: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpValues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dispersion: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispersion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Null Deviance: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullDeviance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/ml/regression.py\u001b[0m in \u001b[0;36mpValues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2955\u001b[0m         \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0melement\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m         \"\"\"\n\u001b[0;32m-> 2957\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pValues\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: degreesOfFreedom must be positive, but got -1.0"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "#spark = SparkSession.builder.appName(\"StockPricePrediction\").getOrCreate()\n",
    "\n",
    "# Assuming your data is in a DataFrame called \"data\"\n",
    "# Replace \"target_column\" with the actual column name of your target variable\n",
    "target_column = 'Adj Close' #\"PercentChangeClose\"\n",
    "features_columns = ['Open', 'High', 'Low', 'Close', 'PercentChangeClose', 'Volume', \n",
    "                    'MarketCap', 'EnterpriseValue', 'PeRatio', 'PsRatio', 'PbRatio', 'EnterprisesValueRevenueRatio', \n",
    "                    'EnterprisesValueEBITDARatio', 'TotalRevenue', 'OperatingRevenue', 'CostOfRevenue', 'GrossProfit', \n",
    "                    'OperatingExpense', 'SellingGeneralAndAdministration', 'OperatingIncome', 'OtherIncomeExpense', 'PretaxIncome', \n",
    "                    'TaxProvision', 'NetIncomeCommonStockholders', 'NetIncome', 'NetIncomeIncludingNoncontrollingInterests', \n",
    "                    'NetIncomeContinuousOperations', 'DilutedNIAvailtoComStockholders', 'BasicEPS', 'DilutedEPS', \n",
    "                    'BasicAverageShares', 'DilutedAverageShares', 'TotalOperatingIncomeAsReported', 'TotalExpenses', \n",
    "                    'NetIncomeFromContinuingAndDiscontinuedOperation', 'NormalizedIncome', 'EBIT', 'EBITDA', \n",
    "                    'ReconciledCostOfRevenue', 'ReconciledDepreciation', 'NetIncomeFromContinuingOperationNetMinorityInterest', \n",
    "                    'NormalizedEBITDA', 'TaxRateForCalcs', 'TotalAssets', 'CurrentAssets', 'CashCashEquivalentsAndShortTermInvestments', \n",
    "                    'CashAndCashEquivalents', 'Receivables', 'Inventory', 'TotalNonCurrentAssets', 'NetPPE', 'GrossPPE', \n",
    "                    'AccumulatedDepreciation', 'GoodwillAndOtherIntangibleAssets', 'OtherIntangibleAssets', 'OtherNonCurrentAssets', \n",
    "                    'TotalLiabilitiesNetMinorityInterest', 'CurrentLiabilities', 'PayablesAndAccruedExpenses', 'Payables', \n",
    "                    'AccountsPayable', 'CurrentDebtAndCapitalLeaseObligation', 'CurrentDebt', \n",
    "                    'TotalNonCurrentLiabilitiesNetMinorityInterest', 'LongTermDebtAndCapitalLeaseObligation', \n",
    "                    'LongTermDebt', 'NonCurrentDeferredLiabilities', 'NonCurrentDeferredTaxesLiabilities', \n",
    "                    'OtherNonCurrentLiabilities', 'TotalEquityGrossMinorityInterest', 'StockholdersEquity', \n",
    "                    'RetainedEarnings', 'TotalCapitalization', 'CommonStockEquity', 'NetTangibleAssets', 'WorkingCapital', \n",
    "                    'InvestedCapital', 'TangibleBookValue', 'TotalDebt', 'ShareIssued', 'OrdinarySharesNumber', \n",
    "                    'OperatingCashFlow', 'CashFlowFromContinuingOperatingActivities', 'NetIncomeFromContinuingOperations', \n",
    "                    'DepreciationAmortizationDepletion', 'DepreciationAndAmortization', 'DeferredTax', 'DeferredIncomeTax', \n",
    "                    'InvestingCashFlow', 'CashFlowFromContinuingInvestingActivities', 'NetPPEPurchaseAndSale', 'PurchaseOfPPE', \n",
    "                    'FinancingCashFlow', 'CashFlowFromContinuingFinancingActivities', 'NetIssuancePaymentsOfDebt', \n",
    "                    'NetCommonStockIssuance', 'CommonStockIssuance', 'CommonStockPayments', 'EndCashPosition', \n",
    "                    'ChangesInCash', 'EffectOfExchangeRateChanges', 'BeginningCashPosition', 'CapitalExpenditure', \n",
    "                    'IssuanceOfCapitalStock', 'RepurchaseOfCapitalStock', 'FreeCashFlow']\n",
    "#features_columns = data3.columns\n",
    "\n",
    "# Assemble the features into a vector\n",
    "assembler = VectorAssembler(inputCols=features_columns, outputCol=\"features\")\n",
    "data_assembled = assembler.transform(data)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(data_assembled)\n",
    "scaledData = scalerModel.transform(data_assembled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(train_data, test_data) = scaledData.randomSplit([0.8, 0.2], seed=3)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr = GeneralizedLinearRegression(labelCol=target_column, featuresCol=\"scaledFeatures\",\n",
    "                      family=\"gaussian\", link=\"identity\",\n",
    "                       maxIter=10,\n",
    "                      regParam=0.3) \n",
    "                      #elasticNetParam=0.8)\n",
    "\n",
    "# Create a pipeline with the assembler and the logistic regression model\n",
    "#pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "# Train the model\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# Print the weights and intercept for linear regression\n",
    "print(\"Weights: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(summary.tValues))\n",
    "print(\"P Values: \" + str(summary.pValues))\n",
    "print(\"Dispersion: \" + str(summary.dispersion))\n",
    "print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "print(\"Deviance: \" + str(summary.deviance))\n",
    "print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "print(\"AIC: \" + str(summary.aic))\n",
    "print(\"Deviance Residuals: \")\n",
    "summary.residuals().show()\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "#predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after PCA with 10 principal components:\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|pca_features                                                                                                                                                                                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[-4.1703293931208374E11,-5.0182670076063324E10,-2.162164279471815E10,-1.1901319780250786E10,-5.136542995668309E9,7.9371988206650505E9,-4.42969712790629E9,-3.5852357384189024E9,-4.359347829229047E9,3.47233841205085E9]      |\n",
      "|[-4.4054031036488184E11,-6.458625688046189E10,-2.1397427174392284E10,-1.0523189281577026E10,-4.467518644461519E9,7.097739778497509E9,-1.3952302529146142E9,-3.6708428329616814E9,-2.870676200629256E9,1.9203154582067976E9]   |\n",
      "|[-4.4807760797445026E11,-7.237894860500839E10,-2.042749866898099E10,-8.98967469583114E9,-1.9057093729084175E9,8.771524056952541E9,5.940142695406686E8,5.05454645396192E9,6.28271985996185E7,-4.399639793588143E8]             |\n",
      "|[-4.499168617494501E11,-8.564590252076465E10,-1.835120221582442E10,-1.5214086586959106E10,-4.71958644234429E9,1.407188076433867E9,-5.774867624375048E8,-5.137384527461737E9,6.505254927792809E8,5.720172651063262E8]          |\n",
      "|[-4.148246580580216E11,-6.000215712747039E10,-1.3394053221629612E10,-1.3866699686285461E10,-1.7903016286523728E9,7.0068090999434E9,-3.20123433866796E9,-6.419928054482521E8,-2.582986823318454E9,1.9657903115579233E9]        |\n",
      "|[-4.5118964629091296E11,-8.423190239911891E10,-1.554957428370888E10,-1.0629821084776743E10,-1.7270080910043666E8,2.8518045871885166E9,7.369940890289491E8,1.2380510464721541E9,6.664883685253738E8,2.4186800643425612E9]      |\n",
      "|[-4.4714780544574536E11,-7.891636104313103E10,-1.6801084161617893E10,-1.3949872733593126E10,-2.0339243949986053E9,-2.7092140647034125E9,9.972713702346499E8,9.015746451139525E8,5.240512089351584E8,2.848449347801505E9]      |\n",
      "|[-4.3178074617367426E11,-6.624698890665925E10,-1.1248084005644407E10,-1.3836055058908997E10,-3.6125894953379357E8,2.2946332543721137E9,6.484735993916599E8,3.3327922841398363E9,6.197246239052892E8,6.41138450336237E9]       |\n",
      "|[-3.957328617014122E11,-4.713776663357499E10,-7.695737945252362E9,-1.3442676000889818E10,-1.3898953979390062E10,2.3031887166885424E9,-2.7361792994678485E8,3.7644909832342615E9,-2.5821309996788354E9,8.103205033384078E8]    |\n",
      "|[-4.0532960996677936E11,-5.482182523817987E10,-7.483113317044735E9,-1.4687102412793987E10,-1.3206669544072823E10,-3.149418120646471E9,-8.606887393590848E8,-8.496280865764401E8,-4.824831495612625E9,6.309262379698267E8]     |\n",
      "|[-3.983435966417047E11,-4.915917988058938E10,-2.7881015261965165E9,-9.622761147447517E9,-7.347834082936326E9,-1.3313627114923863E9,-8.817522985793954E8,8.071225439216439E9,6.825436351988583E8,1.9195762493160858E9]         |\n",
      "|[-4.051100243159433E11,-6.1716431939200455E10,-1.0263876285115169E9,-1.3956653108883331E10,-1.2814659218248173E10,-1.361648910937124E10,-4.327111276022845E9,-1.4078805253258518E10,-3.8464632979448023E9,2.304761383422113E8]|\n",
      "|[-3.8974627369804584E11,-2.48907243321007E10,6.213034156316832E8,7.345895905266671E9,-3.453983421565657E9,3.9459738015438523E9,-3.192765166561951E9,-9.57673636870553E8,-2.403078086626295E9,7.554944954842771E8]             |\n",
      "|[-3.649220255384271E11,-1.0615627326272112E10,7.768438337291068E8,6.232043017942882E9,2.0277377234717894E9,4.677876808353624E9,-3.477946433122571E9,4.9610517072312975E9,-1.4572905486465961E10,1.227428025098233E10]         |\n",
      "|[-3.5772180860365686E11,-1.2641857514098822E10,-6.71768906475143E9,1.371783050026222E10,1.328360232919749E10,1.241310808632319E10,-1.053743516046517E10,1.1693587363991274E10,-2.2536138247828972E8,-3.646499653181643E9]     |\n",
      "|[-3.992134925761956E11,-6.647794929870501E10,-1.8292142428058365E10,7.5757400149978485E9,1.0874932181806072E10,-2.416447393660648E9,-1.1067966867797195E10,-3.6810367534774485E9,-1.8323661718462327E9,1.5971240340850785E9]  |\n",
      "|[-3.9545381231472986E11,-6.042932964879248E10,-1.365160982026655E10,2.9510206100180573E9,3.2041658865103106E9,1.4820338429709654E9,-7.8800047036214485E9,-4.807922708213169E9,-4.242087662628435E9,-3.408430849811595E7]      |\n",
      "|[-3.833793630660363E11,-4.6127411009769424E10,-1.2077328495174496E10,8.622814012104836E9,1.1386787587501188E10,3.5933268065973825E9,-1.035658558381599E10,-3.458638819209839E9,-4.401603787420662E9,2.249395299139629E9]      |\n",
      "|[-3.5651721706702594E11,-3.2482524460848274E10,-1.0660158650495487E10,1.2000596959321997E10,2.54797079725549E9,3.121647749274182E9,-7.887188871870383E9,-6.80763571177487E7,9.887237542007428E8,7.903139716403676E9]          |\n",
      "|[-3.5197073602229443E11,-3.9972429594138855E10,-1.5638179782766607E10,2.058315370216351E10,4.588402887372089E9,-7.306328368512473E9,-1.0574124267996552E10,-3.320383190143232E9,-2.7715825828128254E8,-4.073071024889394E9]   |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "#spark = SparkSession.builder.appName(\"StockPricePrediction\").getOrCreate()\n",
    "\n",
    "# Assuming your data is in a DataFrame called \"data\"\n",
    "# Replace \"target_column\" with the actual column name of your target variable\n",
    "target_column = 'Adj Close' #\"PercentChangeClose\"\n",
    "features_columns = ['Open', 'High', 'Low', 'Close', 'PercentChangeClose', 'Volume', \n",
    "                    'MarketCap', 'EnterpriseValue', 'PeRatio', 'PsRatio', 'PbRatio', 'EnterprisesValueRevenueRatio', \n",
    "                    'EnterprisesValueEBITDARatio', 'TotalRevenue', 'OperatingRevenue', 'CostOfRevenue', 'GrossProfit', \n",
    "                    'OperatingExpense', 'SellingGeneralAndAdministration', 'OperatingIncome', 'OtherIncomeExpense', 'PretaxIncome', \n",
    "                    'TaxProvision', 'NetIncomeCommonStockholders', 'NetIncome', 'NetIncomeIncludingNoncontrollingInterests', \n",
    "                    'NetIncomeContinuousOperations', 'DilutedNIAvailtoComStockholders', 'BasicEPS', 'DilutedEPS', \n",
    "                    'BasicAverageShares', 'DilutedAverageShares', 'TotalOperatingIncomeAsReported', 'TotalExpenses', \n",
    "                    'NetIncomeFromContinuingAndDiscontinuedOperation', 'NormalizedIncome', 'EBIT', 'EBITDA', \n",
    "                    'ReconciledCostOfRevenue', 'ReconciledDepreciation', 'NetIncomeFromContinuingOperationNetMinorityInterest', \n",
    "                    'NormalizedEBITDA', 'TaxRateForCalcs', 'TotalAssets', 'CurrentAssets', 'CashCashEquivalentsAndShortTermInvestments', \n",
    "                    'CashAndCashEquivalents', 'Receivables', 'Inventory', 'TotalNonCurrentAssets', 'NetPPE', 'GrossPPE', \n",
    "                    'AccumulatedDepreciation', 'GoodwillAndOtherIntangibleAssets', 'OtherIntangibleAssets', 'OtherNonCurrentAssets', \n",
    "                    'TotalLiabilitiesNetMinorityInterest', 'CurrentLiabilities', 'PayablesAndAccruedExpenses', 'Payables', \n",
    "                    'AccountsPayable', 'CurrentDebtAndCapitalLeaseObligation', 'CurrentDebt', \n",
    "                    'TotalNonCurrentLiabilitiesNetMinorityInterest', 'LongTermDebtAndCapitalLeaseObligation', \n",
    "                    'LongTermDebt', 'NonCurrentDeferredLiabilities', 'NonCurrentDeferredTaxesLiabilities', \n",
    "                    'OtherNonCurrentLiabilities', 'TotalEquityGrossMinorityInterest', 'StockholdersEquity', \n",
    "                    'RetainedEarnings', 'TotalCapitalization', 'CommonStockEquity', 'NetTangibleAssets', 'WorkingCapital', \n",
    "                    'InvestedCapital', 'TangibleBookValue', 'TotalDebt', 'ShareIssued', 'OrdinarySharesNumber', \n",
    "                    'OperatingCashFlow', 'CashFlowFromContinuingOperatingActivities', 'NetIncomeFromContinuingOperations', \n",
    "                    'DepreciationAmortizationDepletion', 'DepreciationAndAmortization', 'DeferredTax', 'DeferredIncomeTax', \n",
    "                    'InvestingCashFlow', 'CashFlowFromContinuingInvestingActivities', 'NetPPEPurchaseAndSale', 'PurchaseOfPPE', \n",
    "                    'FinancingCashFlow', 'CashFlowFromContinuingFinancingActivities', 'NetIssuancePaymentsOfDebt', \n",
    "                    'NetCommonStockIssuance', 'CommonStockIssuance', 'CommonStockPayments', 'EndCashPosition', \n",
    "                    'ChangesInCash', 'EffectOfExchangeRateChanges', 'BeginningCashPosition', 'CapitalExpenditure', \n",
    "                    'IssuanceOfCapitalStock', 'RepurchaseOfCapitalStock', 'FreeCashFlow']\n",
    "#features_columns = data3.columns\n",
    "\n",
    "# Assemble the features into a vector\n",
    "assembler = VectorAssembler(inputCols=features_columns, outputCol=\"features\")\n",
    "data_assembled = assembler.transform(data)\n",
    "\n",
    "# Apply PCA\n",
    "num_principal_components = 10\n",
    "pca = PCA(k=num_principal_components, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "model = pca.fit(data_assembled)\n",
    "result = model.transform(data_assembled)\n",
    "\n",
    "# Show the result with PCA features\n",
    "print(f\"\\nDataFrame after PCA with {num_principal_components} principal components:\")\n",
    "result.select(\"pca_features\").show(truncate=False)\n",
    "#result.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|             Feature|               Coeff|Coefficient Std Err|             P-value|             T-value|\n",
      "+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|             PeRatio| -1.3657523002323226|0.38712650252711656| 6.81840163709424E-4| -3.5279225041862317|\n",
      "|             PsRatio|   3.022907947488744|  1.159376615277703|0.010795585390354745|  2.6073563220564644|\n",
      "|             PbRatio|  0.8298046014627691| 0.8158312513800045| 0.31201334102836387|  1.0171277455468006|\n",
      "|        TotalRevenue|   2.159815264116857| 1.9412611781284872|  0.2690612438959572|  1.1125835557063328|\n",
      "|         GrossProfit|  -2.164905933739686| 1.8940869071158155| 0.25629354341650834| -1.1429813096782635|\n",
      "|EnterprisesValueR...|   0.513864503418112| 1.1560788717615322|  0.6578320940090812| 0.44448913994520983|\n",
      "|EnterprisesValueE...|0.026467450651519845|    0.6195454298724|  0.9660255178808996| 0.04272075843892677|\n",
      "|    OperatingExpense| -2.6470944424845335| 1.5168093401572444| 0.08461175097829154| -1.7451728258807497|\n",
      "|     OperatingIncome| -1.1731383459412668|  1.281171122164314| 0.36245783300930445| -0.9156765444099733|\n",
      "|           NetIncome| -1.0379167916912122| 1.5616643933924805|  0.5081126659755546| -0.6646221788002058|\n",
      "|            BasicEPS| 0.13270185802545417| 1.6387324608008342|  0.9356517971893132| 0.08097835442925438|\n",
      "|       TotalExpenses|   3.150346087909338| 1.7930606960593278| 0.08256754786346177|  1.7569656703941834|\n",
      "|    NormalizedIncome|  1.1641720697992026|  0.934605627745882| 0.21636383491786582|  1.2456292100519424|\n",
      "|                EBIT|  1.5417004537956427| 1.5841006679091052|  0.3332313730863854|  0.9732338891256024|\n",
      "|              EBITDA|-0.14804725064384222| 1.6851046819693136|  0.9301999124710707|-0.08785641166863616|\n",
      "|         TotalAssets|   7.948201727660355| 1.8346258346305842|4.064041877649416E-5|   4.332328465908029|\n",
      "|CashAndCashEquiva...|  0.3595092088958347| 0.9275385230192119|  0.6992962348038103|  0.3875949084309766|\n",
      "|              NetPPE| -4.4186081919064915|  1.407244013867867|0.002332899269322...| -3.1399019277131393|\n",
      "|            GrossPPE| -2.0635762874364416| 1.7682753598496104| 0.24651285392954891|  -1.166999401955104|\n",
      "|           TotalDebt|   2.299482385943349|  1.184247435578401| 0.05552254227734443|  1.9417246065812706|\n",
      "|    RetainedEarnings|   8.639551338450365|  1.655857178491178|1.286109329701190...|   5.217570362150889|\n",
      "+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "\n",
      "+----------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|         Feature|              Coeff|Coefficient Std Err|             P-value|            T-value|\n",
      "+----------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|         PeRatio|-1.3657523002323226|0.38712650252711656| 6.81840163709424E-4|-3.5279225041862317|\n",
      "|         PsRatio|  3.022907947488744|  1.159376615277703|0.010795585390354745| 2.6073563220564644|\n",
      "|     TotalAssets|  7.948201727660355| 1.8346258346305842|4.064041877649416E-5|  4.332328465908029|\n",
      "|          NetPPE|-4.4186081919064915|  1.407244013867867|0.002332899269322...|-3.1399019277131393|\n",
      "|RetainedEarnings|  8.639551338450365|  1.655857178491178|1.286109329701190...|  5.217570362150889|\n",
      "+----------------+-------------------+-------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Extract p-values or t-values for each feature\n",
    "p_values = summary.pValues\n",
    "t_values = summary.tValues\n",
    "\n",
    "coefficients_double = [float(x) for x in model.coefficients]\n",
    "\n",
    "# Create a DataFrame with feature names, coefficients, p-values, and t-values\n",
    "feature_importance_df = spark.createDataFrame(list(zip(features_columns, coefficients_double, summary.coefficientStandardErrors, p_values, t_values)),\n",
    "                                             [\"Feature\", \"Coeff\", \"Coefficient Std Err\", \"P-value\", \"T-value\"])\n",
    "\n",
    "# Show the feature importance DataFrame\n",
    "feature_importance_df.show(100)\n",
    "\n",
    "# You can filter the DataFrame based on p-values or t-values to identify significant features\n",
    "significant_features = feature_importance_df.filter(F.col(\"P-value\") < 0.05)\n",
    "\n",
    "# Show significant features\n",
    "significant_features.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[Feature: string, Coefficient Std Err: double, P-value: double, T-value: double]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData2.select(\"features\",\"scaledFeatures\").show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "Intercept: 0.044452830188679245\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "#spark = SparkSession.builder.appName(\"StockPricePrediction\").getOrCreate()\n",
    "\n",
    "# Assuming your data is in a DataFrame called \"data\"\n",
    "# Replace \"target_column\" with the actual column name of your target variable\n",
    "target_column2 = \"ROI\"\n",
    "features_columns2 = [\"PeRatio\", \"PsRatio\", \"PbRatio\",\"TotalRevenue\",\"GrossProfit\", \n",
    "                    \"EnterprisesValueRevenueRatio\", \"EnterprisesValueEBITDARatio\", \"OperatingExpense\", \n",
    "                    \"OperatingIncome\", \"NetIncome\", \"BasicEPS\", \"TotalExpenses\", \n",
    "                    \"NormalizedIncome\", \"EBIT\", \"EBITDA\", \"TotalAssets\", \"CashAndCashEquivalents\", \n",
    "                    \"NetPPE\", \"GrossPPE\", \"TotalDebt\", \"RetainedEarnings\"]\n",
    "\n",
    "# Assemble the features into a vector\n",
    "assembler2 = VectorAssembler(inputCols=features_columns2, outputCol=\"features\")\n",
    "data_assembled2 = assembler2.transform(new_df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(train_data2, test_data2) = data_assembled2.randomSplit([0.8, 0.2], seed=3)\n",
    "\n",
    "scaler2 = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel2 = scaler2.fit(train_data2)\n",
    "scaledData2 = scalerModel2.transform(train_data2)\n",
    "\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr2 = LinearRegression(labelCol=target_column2, featuresCol=\"scaledFeatures\",\n",
    "                       maxIter=10,\n",
    "                      regParam=0.3, \n",
    "                      elasticNetParam=0.8)\n",
    "\n",
    "# Create a pipeline with the assembler and the logistic regression model\n",
    "#pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "# Train the model\n",
    "model2 = lr2.fit(scaledData2)\n",
    "\n",
    "# Print the weights and intercept for linear regression\n",
    "print(\"Weights: \" + str(model2.coefficients))\n",
    "print(\"Intercept: \" + str(model2.intercept))\n",
    "\n",
    "# Make predictions on the test set\n",
    "#predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using a binary classification evaluator\n",
    "#evaluator = BinaryClassificationEvaluator(labelCol=target_column)\n",
    "#accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "#print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Optionally, you can print the coefficients of the logistic regression model\n",
    "#print(f\"Coefficients: {model.stages[-1].coefficients}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+\n",
      "|      Date|PercentChangeClose|PercentChangeClose|        prediction|\n",
      "+----------+------------------+------------------+------------------+\n",
      "|12/31/1994|             1.046|             1.046|1.0423654778160092|\n",
      "|12/31/2001|             0.917|             0.917|1.0345627250187255|\n",
      "|12/31/2002|             0.874|             0.874|1.0337084095427078|\n",
      "|12/31/2006|             1.032|             1.032|1.0311428920917847|\n",
      "|12/31/2010|             1.032|             1.032| 1.014177668171415|\n",
      "|12/31/2012|             1.008|             1.008|1.0130504772084732|\n",
      "|12/31/2015|             1.021|             1.021|1.0140466314262975|\n",
      "|12/31/2016|             0.989|             0.989|1.0114795327927955|\n",
      "| 3/31/1990|             1.113|             1.113|1.0490943700162085|\n",
      "| 3/31/1991|             1.087|             1.087|1.0469897861984927|\n",
      "| 3/31/1992|             1.075|             1.075|1.0446434126098443|\n",
      "| 3/31/1995|             1.112|             1.112|1.0428514774540847|\n",
      "| 3/31/1996|             1.085|             1.085|1.0410302340992283|\n",
      "| 3/31/2002|             1.274|             1.274| 1.035007782498837|\n",
      "| 3/31/2007|             1.098|             1.098|1.0310521618302484|\n",
      "| 3/31/2013|             1.145|             1.145|1.0128113684390754|\n",
      "| 3/31/2014|             1.087|             1.087|1.0132733973383177|\n",
      "| 3/31/2015|             0.993|             0.993|1.0132442274048319|\n",
      "| 3/31/2019|             1.028|             1.028|1.0210962165993454|\n",
      "| 6/30/1998|             1.063|             1.063| 1.033268983626423|\n",
      "| 6/30/2001|             0.969|             0.969|1.0355815145969367|\n",
      "| 6/30/2010|              1.04|              1.04| 1.023849275923958|\n",
      "| 6/30/2013|             0.953|             0.953| 1.010369552094729|\n",
      "| 6/30/2017|             1.071|             1.071| 1.016265770105029|\n",
      "| 6/30/2019|             1.081|             1.081|1.0172932388586662|\n",
      "| 6/30/2020|             1.039|             1.039|1.0071406003477126|\n",
      "| 6/30/2022|               1.0|               1.0|1.0112132972200083|\n",
      "| 9/30/1990|             0.994|             0.994| 1.048866103499345|\n",
      "| 9/30/1995|             1.099|             1.099|1.0412127577812544|\n",
      "| 9/30/1998|             0.841|             0.841| 1.035867987142101|\n",
      "| 9/30/2006|             1.057|             1.057| 1.031052319560487|\n",
      "| 9/30/2007|             1.192|             1.192|1.0262070205388552|\n",
      "| 9/30/2010|             1.121|             1.121| 1.021754618249498|\n",
      "| 9/30/2016|              0.98|              0.98| 1.012400693313749|\n",
      "| 9/30/2019|             1.042|             1.042| 1.016920259928908|\n",
      "| 9/30/2023|             0.919|             0.919|1.0105996636593717|\n",
      "+----------+------------------+------------------+------------------+\n",
      "\n",
      "METRICS\n",
      "Mean Squared Error: 0.0068886918752725365\n",
      "R Squared: -0.002984511417331248\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred = model.transform(test_data)\n",
    "lrPred = lrPred.withColumn(\"prediction\", F.abs(lrPred[\"prediction\"]))\n",
    "lrPred.select(\"Date\",\"PercentChangeClose\",\"PercentChangeClose\",\"prediction\").show(100)\n",
    "\n",
    "ev = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"PercentChangeClose\")\n",
    "\n",
    "print(\"METRICS\")\n",
    "print(\"Mean Squared Error:\", ev.evaluate(lrPred, {ev.metricName: \"mse\"}))\n",
    "print(\"R Squared:\", ev.evaluate(lrPred, {ev.metricName:'r2'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------+------------------+\n",
      "|Adj Close|PercentChangeClose|Percent100|        prediction|\n",
      "+---------+------------------+----------+------------------+\n",
      "| 1.957785|             0.956|    95.579|1.0308207547169812|\n",
      "|   2.6057|             1.196|   119.557|1.0308207547169812|\n",
      "| 4.564611|             1.167|    116.73|1.0308207547169812|\n",
      "| 4.719271|             0.933|    93.283|1.0308207547169812|\n",
      "| 4.833506|             0.973|    97.327|1.0308207547169812|\n",
      "| 5.089425|             1.026|   102.629|1.0308207547169812|\n",
      "| 5.205487|             1.103|   110.303|1.0308207547169812|\n",
      "| 7.204547|             1.112|   111.155|1.0308207547169812|\n",
      "|  8.97204|             1.099|   109.898|1.0308207547169812|\n",
      "|11.702862|             0.917|    91.718|1.0308207547169812|\n",
      "+---------+------------------+----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "METRICS\n",
      "Mean Squared Error: 0.008227474095709678\n",
      "R Squared: -0.0005303524442674679\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred2 = model2.transform(test_data)\n",
    "lrPred2 = lrPred2.withColumn(\"prediction\", F.abs(lrPred2[\"prediction\"]))\n",
    "lrPred2.select(\"Adj Close\",\"PercentChangeClose\",\"Percent100\",\"prediction\").show(10)\n",
    "\n",
    "ev2 = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"PercentChangeClose\")\n",
    "\n",
    "print(\"METRICS\")\n",
    "print(\"Mean Squared Error:\", ev2.evaluate(lrPred2, {ev2.metricName: \"mse\"}))\n",
    "print(\"R Squared:\", ev2.evaluate(lrPred2, {ev2.metricName:'r2'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(train_data)\n",
    "scaledData = scalerModel.transform(train_data)\n",
    "\n",
    "scaledData.select(\"high_price\",\"features\",\"scaledFeatures\").show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "lr = LogisticRegression(labelCol='high_price',\n",
    "                        featuresCol='scaledFeatures',\n",
    "                        maxIter=10, \n",
    "                        regParam=0.3, \n",
    "                        elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(scaledData)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred = lrModel.transform(scaledData)\n",
    "lrPred.select('probability','prediction').show(5,truncate=False)\n",
    "\n",
    "# set up evaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"high_price\",\n",
    "                                          metricName=\"areaUnderPR\")\n",
    "\n",
    "# pass to evaluator the DF with predictions, labels\n",
    "aupr = evaluator.evaluate(lrPred)\n",
    "\n",
    "print(\"Area under PR Curve:\", aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS5110 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
